{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 02: Decision Trees, Hidden Markov Models, and Bayesian Reasoning\n",
    "\n",
    "0. Collect suspect statements from the 6 suspects\n",
    "1. Load in the data the police had about each suspect and combine it with the suspect statements\n",
    "2. Use a Decision Tree to try and match the suspects to an alias based on their alleged activities and time spent in each room\n",
    "3. Use an HMM to see how similar the suspect's alleged paths are to the witness statements and GPS data\n",
    "4. Combine the results of the HMM and Decision Tree using Bayesian reasoning to get a final alias matching\n",
    "\n",
    "### Task 0: Collecting Suspect Statements\n",
    "\n",
    "We need to gather more evidence if we're going to be able to figure out who's alibi doesn't hold up. Your next task is to visit each suspect and collect their statements. Only one team member needs to visit each suspect, so feel free to divy up the work. Please go to their offices during the office hours given below and ask them for their statement:\n",
    "\n",
    "```\n",
    "Professor Bui: 2:00 PM - 3:00 PM, Every Day - 326D Cushing\n",
    "\n",
    "Professor Dingler: 2:00 PM - 3:30 PM, Monday, Tuesday, Wednesday, Thursday - 350 Fitz\n",
    "\n",
    "Professor Rehberg: 10:30 AM - 12:00 PM, Tuesday and Thursday - 324 Cushing\n",
    "\n",
    "Professor Levis: 10:30 AM - 11:15 AM, Tuesday and Thursday - 264 Geddes\n",
    "\n",
    "Professor Chambers: Monday 1:00 PM - 3:00 PM and Thursday 2:00 PM - 3:00 PM - 180 Fitz\n",
    "\n",
    "Professor Kumar: 3:25 PM - 4:15 PM, Monday and Wednesday - 378 Fitz\n",
    "```\n",
    "\n",
    "Once you've collected them, add them to the suspect data json files. You may consider trying to find an LLM like ChatGPT-4o to allow you to turn a picture of the statement into the JSON you need.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Load and create the necessary data\n",
    "\n",
    "The starting data is available at [Homework 02 Data](https://drive.google.com/drive/folders/1k9LND_mc5sTLemg77nAOHPq0qLYpEcJM?usp=sharing)\n",
    "\n",
    "After getting in contact with the Theisen-Floyd Estate the police have collected data for past costume parties they've thrown. Turns out there's been a lot of them. They've gathered data on the movement and activity patterns of the aliases. Load those into a dictionary called \"alias_data\" with the format:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"alias_name\": [\n",
    "        {\"suspect_statement\": [...]}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Then you should add the suspect statements to the suspect data json files.\n",
    "\n",
    "Thinking back to class you realize that if you have all of this alias data, you could probably structure this as a supervised learning problem, and a classification task! We could compare our suspect data against the alias data, treating it as the ground-truth, and see if any of the suspects line up against the aliases!\n",
    "\n",
    "Load the suspect data into a dictionary called \"suspect_data\" with the format:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"suspect_name\": [\n",
    "        {\"suspect_statement\": [...], \"gps_data\": [...], \"witness_statements\": {...}}\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "# TODO: Load alias training files\n",
    "alias_data = {}\n",
    "\n",
    "# TODO: Load suspect data\n",
    "suspect_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through the data you have, you realize there's a lot of repeated, overlapping activities and this reminds you of categorical data. You wonder if you could somehow set up a decision tree with the classes being the aliases and then try and match the suspects statements against them!\n",
    "\n",
    "### Task 2: Decision Tree\n",
    "\n",
    "Try training a decision tree classifier to match suspects to the aliases. You'll have to do some feature engineering to get the categorial data we have into a format that can be used by the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Extraction Function\n",
    "\n",
    "We need to somehow turn all of the data we were given into a format that can be used by the decision tree.\n",
    "We can probably calculate how much of their time each suspect spends in each room and maybe we can use activities that suggest a weapon somehow as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Some of the activities seem related to the weapons found at the party, I wonder if we can use that to improve our decision tree.\n",
    "# Note: My solution has three activities per weapon for a total of 18 pairings\n",
    "\n",
    "activity_weapon_mapping = {\n",
    "    'Ripping wippets': 'Gas', # Freebie as an example\n",
    "}\n",
    "\n",
    "# TODO: Write a function to convert the categorical data we have into numerical data for the decision tree\n",
    "def extract_features(data, is_alias=True):\n",
    "    rooms = ['Study', 'Dining Room', 'Kitchen', 'Pantry', 'Living Room', 'Bathroom']\n",
    "    weapons = ['Poison', 'Knife', 'Gas', 'Rope', 'Bag', 'Firearm']\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    room_time = {room: 0 for room in rooms}\n",
    "    activities = []\n",
    "\n",
    "    total_time = 0\n",
    "\n",
    "    # TODO: Count the amount of times the suspect or alias visits each room and a list of activities they do\n",
    "\n",
    "    # TODO: Calculate the percentage of time the suspect or alias spends in each room \n",
    "\n",
    "    # TODO: Create features indicating if an activity they've done suggests a weapon\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "# TODO: Prepare alias training data using the feature extraction function\n",
    "alias_features_dict = {}\n",
    "\n",
    "# TODO: Prepare suspect data using the feature extraction function\n",
    "suspect_features_dict = {}\n",
    "\n",
    "# TODO: Train Decision Tree Classifier\n",
    "# I used the arguments criterion='entropy', random_state=42, max_depth=4, min_samples_split=4\n",
    "# Feel free to play around with different values for the arguments\n",
    "\n",
    "# TODO: Classify Suspects Probabilistically as each Alias\n",
    "\n",
    "# TODO: Print your results and store them for use in the final task\n",
    "decision_tree_results = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference Output:\n",
    "\n",
    "```\n",
    "Probability of Each Suspect Matching Each Alias:\n",
    "\n",
    "            ['Colonel Mustard' 'Miss Scarlet' 'Mr. Green' 'Mrs. Peacock' 'Mrs. White'\n",
    " 'Professor Plum']\n",
    "Professor Bui: ['0.0000', '0.0000', '0.8636', '0.0000', '0.0455', '0.0909']\n",
    "Professor Dingler: ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '1.0000']\n",
    "Professor Rehberg: ['0.5000', '0.0000', '0.0000', '0.5000', '0.0000', '0.0000']\n",
    "Professor Levis: ['0.0000', '0.2000', '0.0000', '0.0000', '0.8000', '0.0000']\n",
    "Professor Chambers: ['0.0000', '0.9412', '0.0000', '0.0000', '0.0000', '0.0588']\n",
    "Professor Kumar: ['0.0000', '0.0000', '0.0000', '1.0000', '0.0000', '0.0000']\n",
    "```\n",
    "\n",
    "Nice! We've got a decision tree that can classify the suspects into the aliases! However lets try and get some more evidence before we make a final decision. The decision tree makes use of the time spent in rooms, but it doesn't consider the paths the suspects take between the rooms. Suddenly inspiration strikes! You recall learning about Hidden Markov Models in class and think that maybe you could use them to get some more evidence!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Hidden Markov Model\n",
    "\n",
    "The police have acquired a blueprint of the estate and based on visitor data the likelihood that a person moves between rooms.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-sp25/nd-cse-30124-sp25.github.io/refs/heads/main/static/img/estate.png\" alt=\"Estate\" style=\"width: 100%; max-width: 800px; height: auto;\">\n",
    "\n",
    "**Note:** I am not an artist don't laugh!\n",
    "\n",
    "The transition probabilities are given below:\n",
    "* Study:\n",
    "    * Dining Room: 0.3\n",
    "    * Living Room: 0.3\n",
    "    * Study: 0.4\n",
    "* Dining Room:\n",
    "    * Kitchen: 0.25\n",
    "    * Study: 0.25\n",
    "    * Living Room: 0.25\n",
    "    * Dining Room: 0.25\n",
    "* Kitchen:\n",
    "    * Dining Room: 0.4\n",
    "    * Pantry: 0.4\n",
    "    * Kitchen: 0.2\n",
    "* Pantry:\n",
    "    * Kitchen: 0.8\n",
    "    * Pantry: 0.2\n",
    "* Living Room:\n",
    "    * Study: 0.25\n",
    "    * Dining Room: 0.25\n",
    "    * Bathroom: 0.25\n",
    "    * Living Room: 0.25\n",
    "* Bathroom:\n",
    "    * Living Room: 0.7\n",
    "    * Bathroom: 0.3\n",
    "\n",
    "Using these, create a \"blueprint\" JSON structure containing:\n",
    "\n",
    "```\n",
    "\"locations\": {\n",
    "    \"ROOM NAME\": {\"id\": \"ROOM ID\", \"adjacent_to\": [\"NEIGHBOR 1\", \"NEIGHBOR 2\"]}\n",
    "    },\n",
    "\"transition_probabilities\": {\n",
    "    \"ROOM ID\": {\n",
    "        \"NEIGHBOR 1 ID\": 0.4,\n",
    "        \"NEIGHBOR 2 ID\": 0.4,\n",
    "        \"ROOM ID\": 0.2\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Using a hidden markov model, find the most likely path for a suspect given the GPS data and witness statements. Then compare the suspect's alleged path from their statement you collected to the most likely path found by the HMM. How similar to the most likely path according to the data is the suspect's path in their statement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# TODO: Create the blueprint dictionary structure\n",
    "\n",
    "# TODO: Initial state distribution (uniform)\n",
    "\n",
    "# TODO: Create the emission probability matrix using objective evidence (GPS and witnesses)\n",
    "def weight_room_matrix(time: str, gps_data: List[Dict], witness_statements: Dict[str, Dict]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create emission probability matrix using objective evidence (GPS and witnesses).\n",
    "    \"\"\"\n",
    "\n",
    "    # Start with uniform distribution\n",
    "    emission = np.ones(n_states) / n_states\n",
    "    \n",
    "    # TODO: 1. Weight based on GPS evidence\n",
    "    \n",
    "    # TODO: 2. Weight based on witness evidence\n",
    "    \n",
    "    # TODO: Normalize Probabilities\n",
    "\n",
    "    return emission\n",
    "\n",
    "# TODO: Use Viterbi algorithm to find most likely sequence of true locations based on GPS and witness data\n",
    "def viterbi(suspect_data: Dict, timestamps: List[str]) -> Tuple[List[str], float]:\n",
    "    \"\"\"\n",
    "    Use Viterbi algorithm to find most likely sequence of true locations.\n",
    "    Also returns the probability of the sequence.\n",
    "    \"\"\"\n",
    "    total_timesteps = len(timestamps)\n",
    "    num_rooms = len(blueprint[\"rooms\"])\n",
    "    \n",
    "    # TODO: Initialize matrices\n",
    "    \n",
    "    \n",
    "    # TODO: Create emission matrices for all timestamps\n",
    "    \n",
    "    # Initialize first timestep\n",
    "    V[0] = np.log(initial) + np.log(emissions[0])\n",
    "    \n",
    "    # TODO: Finish the Viterbi forward pass\n",
    "    for time_step in range(1, total_timesteps):\n",
    "        for _, room_info in blueprint[\"rooms\"].items():\n",
    "\n",
    "            # Calculate probabilities of coming from each previous state\n",
    "            probs = []\n",
    "            for neighbor_room in room_info[\"adjacent_to\"]:\n",
    "                # TODO: Calculate probability of coming from this neighbor\n",
    "                # TODO: Add to probabilities\n",
    "\n",
    "            # TODO: Find most likely previous state\n",
    "\n",
    "    # TODO: Backtrack\n",
    "    \n",
    "    # TODO: Reverse path and convert to room names\n",
    "    \n",
    "    # TODO: Calculate sequence probability\n",
    "    \n",
    "    return room_path, sequence_prob\n",
    "    \n",
    "\n",
    "# TODO: Analyze each suspect's path to determine how well it matches the most likely path from the HMM\n",
    "\n",
    "movement_results = {}\n",
    "\n",
    "print(\"\\nHMM Path Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for suspect_name, suspect in suspect_data.items():\n",
    "    # Get all timestamps in chronological order\n",
    "    timestamps = []\n",
    "    for entry in suspect['suspect_statement']:\n",
    "        timestamps.append(entry['time'])\n",
    "    timestamps.sort()\n",
    "    \n",
    "    # Run Viterbi to get most likely true path using GPS data and witness statements\n",
    "    true_path, path_prob = viterbi(\n",
    "        {\n",
    "            'gps_data': suspect['gps_data'],\n",
    "            'witness_statements': suspect['witness_statements']\n",
    "        }, \n",
    "        timestamps\n",
    "    )\n",
    "    \n",
    "    # TODO: Get suspect's stated path\n",
    "    \n",
    "    # TODO: Calculate matches between true and stated paths\n",
    "    \n",
    "    print(f\"\\n{suspect_name}:\")\n",
    "    print(f'\\tAgreement of Statement Path with HMM Path: {agreement}, Number of Contradictions: {len(true_path) - matches}')\n",
    "\n",
    "    path_agreement = {\n",
    "        'path_probability': path_prob,\n",
    "        'statement_agreement': agreement,\n",
    "        'num_contradictions': len(true_path) - matches\n",
    "    }\n",
    "    \n",
    "    movement_results[suspect_name] = path_agreement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference Results:\n",
    "\n",
    "```\n",
    "HMM Path Analysis:\n",
    "==================================================\n",
    "\n",
    "Professor Bui:\n",
    "\tAgreement of Statement Path with HMM Path: 0.0, Number of Contradictions: 20\n",
    "\n",
    "Professor Dingler:\n",
    "\tAgreement of Statement Path with HMM Path: 0.6, Number of Contradictions: 8\n",
    "\n",
    "Professor Rehberg:\n",
    "\tAgreement of Statement Path with HMM Path: 0.05, Number of Contradictions: 19\n",
    "\n",
    "Professor Levis:\n",
    "\tAgreement of Statement Path with HMM Path: 0.1, Number of Contradictions: 18\n",
    "\n",
    "Professor Chambers:\n",
    "\tAgreement of Statement Path with HMM Path: 0.4, Number of Contradictions: 12\n",
    "\n",
    "Professor Kumar:\n",
    "\tAgreement of Statement Path with HMM Path: 0.1, Number of Contradictions: 18\n",
    "```\n",
    "\n",
    "Nice, now we have two pieces of evidence that we can use to match the suspects to the aliases! If only there were some way to combine them. As you finish your drink you think back to class and remember that you can use Bayesian reasoning to combine the evidence!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Final Bayesian Analysis\n",
    "\n",
    "Perform a final Bayesian analysis to combine the evidence from the decision tree and the Hidden Markov Model to get the likelihood of each suspect matching each alias. Hopefully this will help us figure out who was who!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_evidence_bayesian(aliases, decision_tree_results, hmm_results) -> Dict[str, Dict]:\n",
    "    # TODO: Combine all evidence, assuming that whomever is Mr. Green is lying!\n",
    "    # TODO: P(Alias|Evidence) ∝ P(Alias|Activities) * P(Alias|Truthfulness)\n",
    "\n",
    "    final_results = {}\n",
    "    \n",
    "    # We can assume that whomever is Mr. Green is lying\n",
    "    # So low statement match with highest likelihood path → higher probability of being Mr. Green\n",
    "\n",
    "    for suspect_name in decision_tree_results.keys():\n",
    "        # TODO: Get decision tree probabilities\n",
    "        dt_probs = decision_tree_results[suspect_name]\n",
    "        \n",
    "        # TODO: Get path agreement from the HMM results \n",
    "        path_agreement = hmm_results[suspect_name]['statement_agreement']\n",
    "        \n",
    "        # TODO: Calculate posterior probabilities\n",
    "        posterior = {}\n",
    "        \n",
    "        # TODO: Normalize\n",
    "        \n",
    "        final_results[suspect_name] = { alias: prob/total for alias, prob in posterior.items() }\n",
    "        \n",
    "    return final_results\n",
    "\n",
    "# Combine evidence using Bayesian reasoning\n",
    "final_results = combine_evidence_bayesian(aliases, decision_tree_results, movement_results)\n",
    "\n",
    "for suspect, results in final_results.items():\n",
    "    print(f\"{suspect}:\")\n",
    "    for alias, prob in results.items():\n",
    "        print(f\"  {alias}: {prob:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference Results:\n",
    "\n",
    "```\n",
    "Professor Bui:\n",
    "  Colonel Mustard: 0.000\n",
    "  Miss Scarlet: 0.000\n",
    "  Mr. Green: 1.000\n",
    "  Mrs. Peacock: 0.000\n",
    "  Mrs. White: 0.000\n",
    "  Professor Plum: 0.000\n",
    "Professor Dingler:\n",
    "  Colonel Mustard: 0.000\n",
    "  Miss Scarlet: 0.000\n",
    "  Mr. Green: 0.000\n",
    "  Mrs. Peacock: 0.000\n",
    "  Mrs. White: 0.000\n",
    "  Professor Plum: 1.000\n",
    "Professor Rehberg:\n",
    "  Colonel Mustard: 0.500\n",
    "  Miss Scarlet: 0.000\n",
    "  Mr. Green: 0.000\n",
    "  Mrs. Peacock: 0.500\n",
    "  Mrs. White: 0.000\n",
    "  Professor Plum: 0.000\n",
    "Professor Levis:\n",
    "  Colonel Mustard: 0.000\n",
    "  Miss Scarlet: 0.200\n",
    "  Mr. Green: 0.000\n",
    "  Mrs. Peacock: 0.000\n",
    "  Mrs. White: 0.800\n",
    "  Professor Plum: 0.000\n",
    "Professor Chambers:\n",
    "  Colonel Mustard: 0.000\n",
    "  Miss Scarlet: 0.941\n",
    "  Mr. Green: 0.000\n",
    "  Mrs. Peacock: 0.000\n",
    "  Mrs. White: 0.000\n",
    "  Professor Plum: 0.059\n",
    "Professor Kumar:\n",
    "  Colonel Mustard: 0.000\n",
    "  Miss Scarlet: 0.000\n",
    "  Mr. Green: 0.000\n",
    "  Mrs. Peacock: 1.000\n",
    "  Mrs. White: 0.000\n",
    "  Professor Plum: 0.000\n",
    "```\n",
    "\n",
    "### Success!!\n",
    "\n",
    "We did it, it seems extremely likely that Professor Bui is Mr. Green! You quickly call up Detective Caulfield and explain your findings. He laughs at you. It seems that a purely statistical analysis isn't going to be enough for the authorities to make a warrant. You pour yourself another drink and start brainstorming other ways to find more conclusive evidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
