<!DOCTYPE html>
<html lang="en">
    <head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="">
	<meta name="author" content="">

	<title>Reading 11: Self-Attention, Transformers</title>

	<!-- Bootstrap core CSS -->
	<link href="static/css/blugold.css" rel="stylesheet">
	<script src="https://kit.fontawesome.com/9d2722956c.js" crossorigin="anonymous"></script>

	<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
	<!--[if lt IE 9]>
	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->

	<style>
	body {
	    padding: 10px;
	}
	.resource-list {
	    list-style: none;
	    padding-left: 0;
	    margin-bottom: 1.25em;
	}
	.resource-credit {
	    margin-left: 0.5em;
	    font-size: 0.85em;
	    color: #777;
	    font-style: italic;
	}
	.resource-credit::before {
	    content: "\2014";
	    margin-right: 0.35em;
	}
	</style>
    </head>
    <body>
	<div class="container">

	    <div class="row">
		<div class="page-header">
		    <ul class="nav nav-pills pull-right">
			
			<li><a href="index.html"><i class="fa fa-gavel"></i> <span class="visible-md-inline visible-lg-inline">Home</span></a></li>
			
		    </ul>
		    <h1><i class="fa fa-book"></i> Reading 11: Self-Attention, Transformers</h1>
		</div>
	    </div>

		
<h2 id="self-attention-and-transformers">Self-Attention and Transformers<a class="headerlink" href="#self-attention-and-transformers" title="Permanent link">&para;</a></h2>
<table>
    <tr>
        <td colspan="3">
            
            <div class="row">
    <div class="col-md-4">
        <h4><i class="fa-solid fa-book"></i> Readings</h4>
        <ul class="resource-list">
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://artint.info/3e/html/ArtInt3e.Ch8.S5.html">FCA - Section 8.5.4</a>
                    
                </li>
            
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://probml.github.io/pml-book/book1.html">PML - Section 15.4</a>
                    
                </li>
            
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://d2l.ai/chapter_attention-mechanisms-and-transformers/index.html">D2L - Sections 11.1 through 11.6</a>
                    
                </li>
            
        
            
        
            
        
            
        
            
        
            
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://hannibunny.github.io/mlbook/transformer/attention.html">Attention (HdM)</a>
                    
                </li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
        </ul>
    </div>
    <div class="col-md-4">
        <h4><i class="fa-solid fa-video-camera"></i> Videos</h4>
        <ul class="resource-list">
        
            
        
            
        
            
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://www.youtube.com/watch?v=QAZc9xsQNjQ">Harvard CS50 (35:40 - 54:15)</a>
                    
                </li>
            
        
            
                <li>
                    
                        <i class="fa-solid fa-star" style="color: #f0ad4e;"></i>
                    
                    <a href="https://www.youtube.com/watch?v=eMlx5fFNoYc">3b1b</a>
                    
                </li>
            
        
            
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://youtu.be/PSs6nxngL6k?si=gfuV6LQqtS0jDxQc">Attention (StatQuest)</a>
                    
                </li>
            
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://youtu.be/KphmOJnLAdI?si=dkXEgyn5ImhMdDnD">Matrix Math (StatQuest)</a>
                    
                </li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
        </ul>
    </div>
    <div class="col-md-4">
        <h4><i class="fa-brands fa-python"></i> Notebooks</h4>
        <ul class="resource-list">
        
            
        
            
        
            
        
            
        
            
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://colab.research.google.com/drive/1zrnOd6wE57gefw9VJMFDD_9LTzeng9D8?usp=sharing">Simple Self-Attention</a>
                    
                </li>
            
        
            
        
            
        
            
        
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://github.com/rasbt/machine-learning-book/blob/main/ch16/ch16-part1-self-attention.ipynb">Attention (rasbt)</a>
                    
                </li>
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
        </ul>
    </div>
</div>


<div class="row">
    
        <div class="col-md-4">
            <h4><i class="fa-solid fa-share-alt"></i> Blogposts</h4>
            <ul class="resource-list">
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://lilianweng.github.io/posts/2018-06-24-attention/">Attention (Lilian)</a>
                    
                </li>
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="http://nlp.seas.harvard.edu/annotated-transformer/">Annotated Transformer (Harvard)</a>
                    
                </li>
            
                <li>
                    
                        <i class="fa-solid fa-star" style="color: #f0ad4e;"></i>
                    
                    <a href="https://jalammar.github.io/illustrated-transformer/">Illustrated Transformer (Alammar)</a>
                    
                </li>
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/">Transformers (Lilian)</a>
                    
                </li>
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html">Programming Self-Attention (Raschka)</a>
                    
                </li>
            
            </ul>
        </div>
        <div class="col-md-8">
            <h4><i class="fa-solid fa-file-pdf"></i> Papers</h4>
            <ul class="resource-list">
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need (Vaswani et al.)</a>
                    
                </li>
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://arxiv.org/pdf/2302.07730">Transformer Family Tree (Amatriain et al.)</a>
                    
                </li>
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://arxiv.org/pdf/1810.04805">BERT Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al.)</a>
                    
                </li>
            
                <li>
                    
                        <span style="display:inline-block; width: 1em;">&bull;</span>
                    
                    <a href="https://gwern.net/doc/www/s3-us-west-2.amazonaws.com/d73fdc5ffa8627bce44dcda2fc012da638ffb158.pdf">Improving Language Understanding by Generative Pre-Training (Radford et al.)</a>
                    
                </li>
            
            </ul>
        </div>
    
</div>

        </td>
    </tr>
</table>

<h2 id="quiz">Quiz<a class="headerlink" href="#quiz" title="Permanent link">&para;</a></h2>


	    <div class="row">
		<hr/>

		<footer class="text-center">
		    <p class="text-muted">
		    <small>
		    Built using
		    <a href="http://twitter.github.com/bootstrap/">Bootstrap</a>,
		    <a href="http://fortawesome.github.com/Font-Awesome/">Font Awesome</a>, and
		    <a href="http://www.python.org/">Python</a>.
		    <br/>
		    &copy; 2022 <a href="http://www.nd.edu">University of Notre Dame</a>
		    </small>
		    </p>
		</footer>
	    </div>

	</div> <!-- /container -->

	<!-- Bootstrap core JavaScript
	================================================== -->
	<!-- Placed at the end of the document so the pages load faster -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
	
	
    </body>
</html>

