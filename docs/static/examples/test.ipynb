{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder...\n",
      "Epoch [100/2000], Loss: 0.2513\n",
      "Epoch [200/2000], Loss: 0.2460\n",
      "Epoch [300/2000], Loss: 0.2406\n",
      "Epoch [400/2000], Loss: 0.2347\n",
      "Epoch [500/2000], Loss: 0.2296\n",
      "Epoch [600/2000], Loss: 0.2236\n",
      "Epoch [700/2000], Loss: 0.2183\n",
      "Epoch [800/2000], Loss: 0.2142\n",
      "Epoch [900/2000], Loss: 0.2112\n",
      "Epoch [1000/2000], Loss: 0.2095\n",
      "Epoch [1100/2000], Loss: 0.2083\n",
      "Epoch [1200/2000], Loss: 0.2073\n",
      "Epoch [1300/2000], Loss: 0.2062\n",
      "Epoch [1400/2000], Loss: 0.2051\n",
      "Epoch [1500/2000], Loss: 0.2039\n",
      "Epoch [1600/2000], Loss: 0.2026\n",
      "Epoch [1700/2000], Loss: 0.2009\n",
      "Epoch [1800/2000], Loss: 0.1992\n",
      "Epoch [1900/2000], Loss: 0.1975\n",
      "Epoch [2000/2000], Loss: 0.1960\n",
      "\n",
      "Testing autoencoder...\n",
      "\n",
      "Original -> Latent -> Reconstructed (rounded):\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[6.3811399e-32 1.8662856e-04 4.2624983e-05 3.6060226e-01 4.4595975e-01\n",
      " 4.6022129e-01 4.8050037e-01 4.9308878e-01]\n",
      "Number: 0, Binary: [0. 0. 0. 0. 0. 0. 0. 0.], Latent: 0.3117, Latent Int: 0, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[1.6673907e-32 1.6452506e-04 3.5732875e-05 3.5756904e-01 4.4480205e-01\n",
      " 4.5995644e-01 4.8024431e-01 4.9250689e-01]\n",
      "Number: 1, Binary: [0. 0. 0. 0. 0. 0. 0. 1.], Latent: 0.5193, Latent Int: 1, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[4.3568556e-33 1.4503916e-04 2.9955156e-05 3.5454720e-01 4.4364488e-01\n",
      " 4.5969167e-01 4.7998828e-01 4.9192500e-01]\n",
      "Number: 2, Binary: [0. 0. 0. 0. 0. 0. 1. 0.], Latent: 0.1395, Latent Int: 2, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[1.1384630e-33 1.2786058e-04 2.5111554e-05 3.5153690e-01 4.4248837e-01\n",
      " 4.5942685e-01 4.7973228e-01 4.9134308e-01]\n",
      "Number: 3, Binary: [0. 0. 0. 0. 0. 0. 1. 1.], Latent: 0.3472, Latent Int: 3, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[2.97480174e-34 1.12716625e-04 2.10511644e-05 3.48538369e-01\n",
      " 4.41332489e-01 4.59162056e-01 4.79476213e-01 4.90761280e-01]\n",
      "Number: 4, Binary: [0. 0. 0. 0. 0. 1. 0. 0.], Latent: 0.3830, Latent Int: 4, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[7.7730919e-35 9.9365978e-05 1.7647268e-05 3.4555179e-01 4.4017717e-01\n",
      " 4.5889732e-01 4.7922021e-01 4.9017942e-01]\n",
      "Number: 5, Binary: [0. 0. 0. 0. 0. 1. 0. 1.], Latent: 0.5907, Latent Int: 5, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[2.0311231e-35 8.7596673e-05 1.4793831e-05 3.4257734e-01 4.3902257e-01\n",
      " 4.5863268e-01 4.7896421e-01 4.8959756e-01]\n",
      "Number: 6, Binary: [0. 0. 0. 0. 0. 1. 1. 0.], Latent: 0.2109, Latent Int: 6, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "[5.30740219e-36 7.72211861e-05 1.24017115e-05 3.39615196e-01\n",
      " 4.37868595e-01 4.58367944e-01 4.78708208e-01 4.89015847e-01]\n",
      "Number: 7, Binary: [0. 0. 0. 0. 0. 1. 1. 1.], Latent: 0.4185, Latent Int: 7, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1.3868232e-36 6.8074485e-05 1.0396386e-05 3.3666551e-01 4.3671533e-01\n",
      " 4.5810324e-01 4.7845227e-01 4.8843408e-01]\n",
      "Number: 8, Binary: [0. 0. 0. 0. 1. 0. 0. 0.], Latent: 0.2342, Latent Int: 8, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[3.6237390e-37 6.0011240e-05 8.7153467e-06 3.3372858e-01 4.3556273e-01\n",
      " 4.5783862e-01 4.7819626e-01 4.8785236e-01]\n",
      "Number: 9, Binary: [0. 0. 0. 0. 1. 0. 0. 1.], Latent: 0.4418, Latent Int: 9, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[9.4688237e-38 5.2903019e-05 7.3061137e-06 3.3080447e-01 4.3441084e-01\n",
      " 4.5757401e-01 4.7794032e-01 4.8727065e-01]\n",
      "Number: 10, Binary: [0. 0. 0. 0. 1. 0. 1. 0.], Latent: 0.0621, Latent Int: 10, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "[2.4742396e-38 4.6636669e-05 6.1247283e-06 3.2789335e-01 4.3325961e-01\n",
      " 4.5730940e-01 4.7768441e-01 4.8668909e-01]\n",
      "Number: 11, Binary: [0. 0. 0. 0. 1. 0. 1. 1.], Latent: 0.2697, Latent Int: 11, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[3.0705372e-38 5.2732219e-05 8.2727793e-06 3.3178446e-01 4.3437806e-01\n",
      " 4.5821521e-01 4.7822484e-01 4.8696798e-01]\n",
      "Number: 12, Binary: [0. 0. 0. 0. 1. 1. 0. 0.], Latent: 0.3056, Latent Int: 12, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 1. 1. 0. 1.]\n",
      "[8.6554036e-38 6.7974972e-05 1.4365041e-05 3.3932325e-01 4.3669370e-01\n",
      " 4.5973793e-01 4.7918484e-01 4.8770013e-01]\n",
      "Number: 13, Binary: [0. 0. 0. 0. 1. 1. 0. 1.], Latent: 0.5132, Latent Int: 13, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "[0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "[2.4398709e-37 8.7623492e-05 2.4943623e-05 3.4694433e-01 4.3901214e-01\n",
      " 4.6126142e-01 4.8014492e-01 4.8843238e-01]\n",
      "Number: 14, Binary: [0. 0. 0. 0. 1. 1. 1. 0.], Latent: 0.1334, Latent Int: 14, Reconstructed: [0 0 0 0 0 0 0 0], As Int: 0\n",
      "\n",
      "Bit-level accuracy: 61.62%\n",
      "Perfect reconstruction rate: 1.95%\n",
      "\n",
      "Model saved to 'binary_autoencoder.pth'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "class BinaryAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=8, latent_dim=1):\n",
    "        super(BinaryAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder: 8 binary digits -> 1 condensed representation\n",
    "        self.encoder = nn.Sequential(\n",
    "            # nn.Linear(input_dim, 6),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(6, 4),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            # nn.Linear(4, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Decoder: 1 condensed representation -> 8 binary digits\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 2),\n",
    "            # nn.ReLU(),\n",
    "            torch.sin(),\n",
    "            nn.Linear(2, 3),\n",
    "            torch.sin(),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(3, 4),\n",
    "            torch.sin(),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(4, 5),\n",
    "            torch.sin(),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(5, input_dim),\n",
    "            nn.Sigmoid()  # Output between 0 and 1 for binary reconstruction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode the input\n",
    "        latent = self.encoder(x)\n",
    "\n",
    "        latent_ints = []\n",
    "        for inp in x:\n",
    "            latent_int = np.array([sum(2 ** i for i, _ in enumerate(reversed(inp)) if _ == 1)])\n",
    "            latent_ints.append(latent_int)\n",
    "\n",
    "        latent_int = np.array(latent_ints)\n",
    "\n",
    "        # Decode the latent representation\n",
    "        reconstructed = self.decoder(torch.tensor(latent_int, dtype=torch.float32))\n",
    "        return reconstructed, latent, latent_int\n",
    "\n",
    "# Generate training data (binary representations of 0-255)\n",
    "def generate_binary_data():\n",
    "    data = []\n",
    "    for i in range(256):\n",
    "        # Convert to binary and pad to 8 digits\n",
    "        binary = format(i, '08b')\n",
    "        # Convert binary string to list of floats\n",
    "        binary_list = [float(bit) for bit in binary]\n",
    "        data.append(binary_list)\n",
    "    return torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "# Main training function\n",
    "def train_autoencoder(epochs=1000, learning_rate=0.001):\n",
    "    # Generate the dataset\n",
    "    binary_data = generate_binary_data()\n",
    "    \n",
    "    # Create the model, loss function, and optimizer\n",
    "    model = BinaryAutoencoder()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        reconstructed, latent, latent_int = model(binary_data)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(reconstructed, binary_data)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print progress every 100 epochs\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test the autoencoder\n",
    "def test_autoencoder(model, num_to_test=10):\n",
    "    binary_data = generate_binary_data()\n",
    "    \n",
    "    # Get reconstructions\n",
    "    with torch.no_grad():\n",
    "        reconstructed, latent, latent_int = model(binary_data)\n",
    "    \n",
    "    # Print results for a few examples\n",
    "    print(\"\\nOriginal -> Latent -> Reconstructed (rounded):\")\n",
    "    for i in range(num_to_test):\n",
    "        original = binary_data[i].numpy()\n",
    "        print(original)\n",
    "        latent_val = latent[i].item()\n",
    "        recon = reconstructed[i].numpy()\n",
    "        print(recon)\n",
    "        recon_rounded = np.round(recon).astype(int)\n",
    "        \n",
    "        # Convert binary arrays to integers for readability\n",
    "        original_int = int(''.join(map(str, original.astype(int))), 2)\n",
    "        recon_int = int(''.join(map(str, recon_rounded)), 2)\n",
    "        \n",
    "        print(f\"Number: {original_int}, Binary: {original}, Latent: {latent_val:.4f}, Latent Int: {latent_int[i].item()}, Reconstructed: {recon_rounded}, As Int: {recon_int}\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    rounded_reconstructed = torch.round(reconstructed)\n",
    "    accuracy = (rounded_reconstructed == binary_data).float().mean().item() * 100\n",
    "    print(f\"\\nBit-level accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Calculate perfect reconstructions (all 8 bits correct)\n",
    "    perfect_reconstructions = torch.all(rounded_reconstructed == binary_data, dim=1).float().mean().item() * 100\n",
    "    print(f\"Perfect reconstruction rate: {perfect_reconstructions:.2f}%\")\n",
    "\n",
    "# Run the training and testing\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Training autoencoder...\")\n",
    "    trained_model = train_autoencoder(epochs=2000)\n",
    "    \n",
    "    print(\"\\nTesting autoencoder...\")\n",
    "    test_autoencoder(trained_model, num_to_test=15)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(trained_model.state_dict(), \"binary_autoencoder.pth\")\n",
    "    print(\"\\nModel saved to 'binary_autoencoder.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
